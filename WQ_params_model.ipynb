{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdf7a4c",
   "metadata": {},
   "source": [
    "Read Water quality parameters from shapefile\n",
    "List all satellite dates \n",
    "find nearest satellite image for each measurement\n",
    "associate satellite bands for each measurement\n",
    "train models \n",
    "evaluate results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#Uncomment the satellite to run\n",
    "satellite=\"Landsat\" \n",
    "satellite='Sentinel_2'\n",
    "satellite='Planet_Scope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mport xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "#initialize variables \n",
    "DATA_DIR='DATA/vrana/Landsat_new'\n",
    "file_bands='DATA/bands_landsat.csv'\n",
    "band_names = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\", \"B10\"]\n",
    "\n",
    "\n",
    "#define correct variables for each satellite \n",
    "if satellite== 'Landsat':\n",
    "    DATA_DIR='DATA/vrana/Landsat_new'\n",
    "    file_bands='DATA/bands_landsat.csv'\n",
    "\n",
    " \n",
    "    band_names = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\", \"B10\"]\n",
    "if satellite=='Sentinel_2':\n",
    "    DATA_DIR='DATA/vrana/Sentinel_new'\n",
    "    file_bands='DATA/bands_sentinel.csv'\n",
    "\n",
    "    band_names = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "  \n",
    "if satellite=='Planet_Scope':\n",
    "    DATA_DIR='DATA/vrana/transfer.pcloud.PnXOdLhM'\n",
    "    band_names = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8' ]\n",
    "    file_bands='DATA/bands_planet.csv'\n",
    "\n",
    " \n",
    "print(satellite)\n",
    "in_sutu_m = gpd.read_file('DATA/vrana/in_situ_230_standardize_32633.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "base_path = DATA_DIR\n",
    " \n",
    "if os.path.exists(file_bands):\n",
    "    print(\"File exists!\")\n",
    "    df=pd.read_csv(file_bands)\n",
    "else:\n",
    "    in_sutu_m['date']=pd.to_datetime(in_sutu_m['DATUM'])\n",
    "    dates = []\n",
    "    folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "\n",
    "    for folder in folders:\n",
    "        # Match the date pattern YYYYMMDD\n",
    "        match = re.search(r\"(\\d{8})\", folder)\n",
    "        if match:\n",
    "            date_str = match.group(1)  # '20230716'\n",
    "            date_obj = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "            dates.append(date_obj)\n",
    "\n",
    "    print(\"Extracted dates:\", dates)\n",
    "    print(\"File does not exist.\") \n",
    "    # --- Step 1: Extract folder dates and map to folder paths ---\n",
    "    folder_date_map = {}\n",
    "    for f in os.listdir(base_path):\n",
    "        full_path = os.path.join(base_path, f)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"(\\d{8})\", f)\n",
    "            if match:\n",
    "                date_obj = datetime.strptime(match.group(1), \"%Y%m%d\")\n",
    "                folder_date_map[date_obj] = full_path\n",
    "\n",
    "    folder_dates = sorted(folder_date_map.keys())\n",
    "\n",
    "    # --- Step 2: Example gdf with geometry + date column ---\n",
    "    # gdf = gpd.read_file(\"points.geojson\")\n",
    "    # gdf['date'] = pd.to_datetime(gdf['date'])\n",
    "    gdf=in_sutu_m.copy()\n",
    "    gdf['datum_Sat']=gdf['date']\n",
    "    # --- Helper to find nearest available folder date ---\n",
    "    def find_nearest_date(target_date, date_list):\n",
    "        return min(date_list, key=lambda d: abs(d - target_date))\n",
    "\n",
    "    # --- Step 3: Extract pixel values into separate band columns ---\n",
    "    \n",
    "    # Prepare empty columns in gdf\n",
    "    for b in band_names:\n",
    "        gdf[b] = None\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        nearest_date = find_nearest_date(row['date'], folder_dates)\n",
    "        folder_path = folder_date_map[nearest_date]\n",
    "        print(row['date'],nearest_date,folder_path)\n",
    "\n",
    "        point = row.geometry\n",
    "\n",
    "        # Read TIFFs from folder\n",
    "        tiff_files = sorted([f for f in os.listdir(folder_path) if (f.lower().endswith('.tiff') or f.lower().endswith('.tif'))])\n",
    "\n",
    "        for tiff_file in tiff_files:\n",
    "            # Extract band code from filename (e.g., 'B04')\n",
    "            if satellite==\"Planet_Scope\":\n",
    "                    match_band = re.search(r'B(\\d{1,2}[A]?)', tiff_file)\n",
    "            else:\n",
    "                    match_band = re.search(r'_B(\\d+[A]?)_', tiff_file)\n",
    "            if match_band:\n",
    "                band_code = \"B\" + match_band.group(1)\n",
    "\n",
    "                if band_code in band_names:\n",
    "                    with rasterio.open(os.path.join(folder_path, tiff_file)) as src:\n",
    "                        # Ensure CRS matches\n",
    "                        if gdf.crs != src.crs:\n",
    "                            point = gdf.to_crs(src.crs).iloc[idx].geometry\n",
    "                        val = list(src.sample([(point.x, point.y)]))[0][0]\n",
    "                        gdf.at[idx, band_code] = val\n",
    "                        gdf.at[idx, 'datum_Sat'] = nearest_date\n",
    "                    \n",
    "                        print(idx,row['date'],band_code,val,nearest_date )\n",
    "    df=gdf.dropna().copy()\n",
    "    df.to_csv(file_bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Regression models\n",
    " \n",
    "from sklearn.linear_model import  RANSACRegressor, PoissonRegressor, LinearRegression, Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ----- CONFIGURATION -----\n",
    "# Define input and output columns\n",
    "#in_X_cols = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "#out_Y_cols = ['IRB_EC_MIN', 'IRB_TUR_MI', 'IRB_WT_MIN', 'IRB_DO_MIN']\n",
    "out_Y_cols =['IRB_EC', 'IRB_TUR', 'IRB_WT', 'IRB_DO']\n",
    "\n",
    "in_X_cols=band_names\n",
    "# ----- LOAD & PREPARE DATA -----\n",
    " # Replace with your actual DataFrame\n",
    "df = df.dropna(subset=in_X_cols + out_Y_cols)\n",
    "\n",
    "X = df[in_X_cols].values\n",
    "y = df[out_Y_cols].values  # multivariate regression\n",
    "\n",
    "# Standardize features\n",
    "'''scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----- MODELS TO BENCHMARK -----\n",
    "# ----- MODELS TO BENCHMARK -----\n",
    "models1 = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    'RANSACRegressor': RANSACRegressor(),\n",
    "     \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    'PoissonRegressor': PoissonRegressor()\n",
    "}\n",
    "\n",
    "# ----- BENCHMARK LOOP -----\n",
    "print(f\"{'Model':<25} {'MAE':>10} {'RMSE':>10} {'RÂ²':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, model in models1.items():\n",
    "    try:\n",
    "        # For models that do not support multi-output, loop over targets\n",
    "        \n",
    "        if y_train.shape[1] > 1 and not hasattr(model, 'multioutput'):\n",
    "            preds = []\n",
    "            for i in range(y_train.shape[1]):\n",
    "                model.fit(X_train, y_train[:, i])\n",
    "                pred = model.predict(X_test)\n",
    "                preds.append(pred)\n",
    "            y_pred = np.stack(preds, axis=1)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        # Inverse scale\n",
    "        #y_test_orig = scaler_y.inverse_transform(y_test)\n",
    "        #y_pred_orig = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "        # Compute metrics averaged across all output variables\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{name:<25} {mae:10.3f} {rmse:10.3f} {r2:10.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<25} ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d645a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, RANSACRegressor, PoissonRegressor, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "X = df[in_X_cols].values\n",
    "y = df[out_Y_cols].values  # multivariate regression\n",
    "\n",
    "# Standardize features\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----- MODELS TO BENCHMARK -----\n",
    "models1 = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    'RANSACRegressor': RANSACRegressor(),\n",
    "     \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    'PoissonRegressor': PoissonRegressor()\n",
    "}\n",
    "n_targets = y_train.shape[1]\n",
    "\n",
    "# ----- LATEX HEADER -----\n",
    "print(\"\\\\begin{table}[h]\")\n",
    "print(\"\\\\centering\")\n",
    "\n",
    "# column format: 1 for model + 1 per target\n",
    "col_format = \"l\" + \"c\" * n_targets\n",
    "print(f\"\\\\begin{{tabular}}{{{col_format}}}\")\n",
    "print(\"\\\\hline\")\n",
    "\n",
    "# header row\n",
    "header = \"Model\"\n",
    "for i in range(n_targets):\n",
    "    header += f\" & {out_Y_cols[i]} (MAE, RMSE, R\\\\^2)\"\n",
    "print(header + \" \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "\n",
    "# ----- BENCHMARK LOOP -----\n",
    "for name, model in models1.items():\n",
    "    row = name\n",
    "    try:\n",
    "        for i in range(n_targets):\n",
    "            # Train on single target\n",
    "            model.fit(X_train, y_train[:, i])\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Construct placeholders for scaler (full shape)\n",
    "            y_test_full = np.zeros_like(y_test)\n",
    "            y_pred_full = np.zeros_like(y_test)\n",
    "            y_test_full[:, i] = y_test[:, i]\n",
    "            y_pred_full[:, i] = y_pred\n",
    "\n",
    "            # Inverse scaling\n",
    "            y_test_orig = scaler_y.inverse_transform(y_test_full)[:, i]\n",
    "            y_pred_orig = scaler_y.inverse_transform(y_pred_full)[:, i]\n",
    "\n",
    "            # Metrics\n",
    "            mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "            r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "            row += f\" & ({mae:.3f}, {rmse:.3f}, {r2:.3f})\"\n",
    "    except Exception as e:\n",
    "        row += \" & ERROR\" * n_targets\n",
    "\n",
    "    print(row + \" \\\\\\\\\")\n",
    "\n",
    "# ----- LATEX FOOTER -----\n",
    "print(\"\\\\hline\")\n",
    "print(\"\\\\end{tabular}\")\n",
    "print(\"\\\\caption{Benchmark results of regression models for each target variabl for \"+ satellite +\"}\")\n",
    "print(\"\\\\label{tab:benchmark_results}\")\n",
    "print(\"\\\\end{table}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
