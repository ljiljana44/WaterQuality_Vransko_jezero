{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f04054",
   "metadata": {},
   "source": [
    "<li>Read water quality points and class from shapefile \n",
    "<li>list all satellite images \n",
    "<li>read satellite bands for points \n",
    "<li>create spectral or temporal dataset \n",
    "<li>train model\n",
    "<li>test model \n",
    "<li>predict future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b1397",
   "metadata": {},
   "source": [
    "<h1>install </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c562985",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas geopandas  rasterio tensorflow xgboost scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95840528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the satellite to run\n",
    "satellite=\"Landsat\" \n",
    "#satellite='Sentinel_2'\n",
    "#satellite='Planet_Scope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mport xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "#initialize variables \n",
    "DATA_DIR='DATA/vrana/Landsat_new'\n",
    "file_timeseries='temp_tsdf_landsat.csv'\n",
    "future_path='DATA/vrana/Future/Landsat_SR'\n",
    "band_names = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\", \"B10\"]\n",
    "\n",
    "\n",
    "#define correct variables for each satellite \n",
    "if satellite== 'Landsat':\n",
    "    DATA_DIR='DATA/vrana/Landsat_new'\n",
    "    file_timeseries='temp_tsdf_landsat.csv'\n",
    "    future_path='DATA/vrana/Future/Landsat_SR'\n",
    "    band_names = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\", \"B10\"]\n",
    "if satellite=='Sentinel_2':\n",
    "    DATA_DIR='DATA/vrana/Sentinel_new'\n",
    "    band_names = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "    file_timeseries='temp_tsdf_sentinel.csv'\n",
    "    future_path = 'DATA/vrana/Future/Sentinel/'\n",
    "if satellite=='Planet_Scope':\n",
    "    DATA_DIR='DATA/vrana/transfer.pcloud.PnXOdLhM'\n",
    "    band_names = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8' ]\n",
    "    file_timeseries='temp_tsdf_planetscope.csv'\n",
    "    future_path = 'DATA/vrana/Future/Planet/'\n",
    "\n",
    " \n",
    "print(satellite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "WQ_points = gpd.read_file('DATA/vrana/AHP_WQI_0411_points_300x300.shp')\n",
    "WQ_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79036b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "base_path = DATA_DIR\n",
    "if os.path.exists(file_timeseries):\n",
    "    print(\"File exists!\")\n",
    "    tsdf=pd.read_csv(file_timeseries)\n",
    "else:\n",
    "    print(\"File does not exist.\") \n",
    "# --- Step 1: Extract folder dates and map to folder paths ---\n",
    "    folder_date_map = {}\n",
    "    for f in os.listdir(base_path):\n",
    "        full_path = os.path.join(base_path, f)\n",
    "        if os.path.isdir(full_path):\n",
    "            match = re.search(r\"(\\d{8})\", f)\n",
    "            if match:\n",
    "                date_obj = datetime.strptime(match.group(1), \"%Y%m%d\")\n",
    "                folder_date_map[date_obj] = full_path\n",
    "\n",
    "    folder_dates = sorted(folder_date_map.keys())\n",
    "    print(folder_dates)\n",
    "     # --- Step 2: Example gdf with geometry + date column ---\n",
    " \n",
    "    gdf=WQ_points.copy()\n",
    "    # --- Helper to find nearest available folder date ---\n",
    "    def find_nearest_date(target_date, date_list):\n",
    "        return min(date_list, key=lambda d: abs(d - target_date))\n",
    "\n",
    "    # --- Step 3: Extract pixel values into separate band columns ---\n",
    "\n",
    "    final1=[]\n",
    "    for d in folder_date_map.keys():\n",
    "        folder_path=folder_date_map[d]\n",
    "        tiff_files = sorted([f for f in os.listdir(folder_path) if (f.lower().endswith('.tiff') or f.lower().endswith('.tif'))])\n",
    "        \n",
    "        for tiff_file in tiff_files:\n",
    "            # Extract band code from filename (e.g., 'B04')\n",
    "            #print(tiff_file)\n",
    "            if satellite==\"Planet_Scope\":\n",
    "                match_band = re.search(r'B(\\d{1,2}[A]?)', tiff_file)\n",
    "            else:\n",
    "                match_band = re.search(r'_B(\\d+[A]?)_', tiff_file)\n",
    "            #print(match_band)\n",
    "            if match_band:\n",
    "                band_code = \"B\" + match_band.group(1)\n",
    "\n",
    "                if band_code in band_names:\n",
    "                    #print(d,band_code)\n",
    "                    with rasterio.open(os.path.join(folder_path, tiff_file)) as src:\n",
    "                        # Ensure CRS matches\n",
    "                        \n",
    "                            \n",
    "                        for idx, row  in gdf.iterrows():\n",
    "                            \n",
    "                            point = gdf.to_crs(src.crs).iloc[idx].geometry\n",
    "                            if gdf.crs != src.crs:\n",
    "                                point = gdf.to_crs(src.crs).iloc[idx].geometry\n",
    "                            #print(list(src.sample([(point.x, point.y)])))\n",
    "                            val = list(src.sample([(point.x, point.y)]))[0][0]\n",
    "                            final1.append({'ponit':point,'pontid':idx,'date':d,'band':band_code,'val':val,'WQI':row['WQI'],\t'Class': row.Class})\n",
    "\n",
    "                            \n",
    "    print(final1)                \n",
    "    tsdf=pd.DataFrame(final1)\n",
    "    tsdf.to_csv(file_timeseries)\n",
    "tsdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fb58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Make sure date is datetime\n",
    "tsdf['date'] = pd.to_datetime(tsdf['date'])\n",
    "\n",
    "# Pivot: one row per (pontid, date), columns are bands\n",
    "df_wide = tsdf.pivot_table(\n",
    "    index=['pontid',  'date', 'WQI', 'Class'],\n",
    "    columns='band',\n",
    "    values='val'\n",
    ").reset_index()\n",
    "\n",
    "# Sort only by pontid  and date\n",
    "df_wide = df_wide.sort_values(['pontid', 'date'])\n",
    "\n",
    "X_list = []\n",
    "ids_list = []\n",
    "dates_list = []\n",
    "class_list={}\n",
    "Wqi={}\n",
    "band_order = band_names#[\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B07\",\"B06\", \"B10\"]\n",
    "for pid, group in df_wide.groupby('pontid'):\n",
    "    group = group.sort_values('date')\n",
    "    ts_array = group[band_order].to_numpy(dtype=np.float32)  # shape: (num_times, num_bands)\n",
    "    X_list.append(ts_array)\n",
    "    ids_list.append(pid)\n",
    "    dates_list.append(group['date'].to_numpy())\n",
    "    class_list[pid]=int(group['Class'].max())\n",
    "  \n",
    "    Wqi[pid]=group['WQI'].max()\n",
    "max_len = max(ts.shape[0] for ts in X_list)\n",
    "num_bands = len(band_names)\n",
    "\n",
    "# Pad sequences on time axis\n",
    "X_padded = pad_sequences(\n",
    "    X_list,\n",
    "    maxlen=max_len,\n",
    "    dtype='float32',\n",
    "    padding='post',\n",
    "    value=0.0\n",
    ")  # shape: (num_points, max_len, num_bands)\n",
    "X_spectral = np.transpose(X_padded, (0, 2, 1))\n",
    "spec=\"spectral\"\n",
    "# shape: (num_points, num_bands, max_len)\n",
    "y=list(class_list.values())\n",
    "\n",
    "X_spectral.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4b6eb",
   "metadata": {},
   "source": [
    "<h1> Define Functions </h1>\n",
    "\n",
    "Definition of model, function for plotting model training history and confusion matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build CNN ---\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense, Dropout, BatchNormalization, Input\n",
    "def train_model(X_train,X_test,y_train,y_test):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),  # (bands, time)\n",
    "\n",
    "        Conv1D(16, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # --- Train ---\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=500,\n",
    "        batch_size=16,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n",
    "    return model, history\n",
    "    \n",
    "def plot_history(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def plot_confusion_matrix(model, X_train,X_test,y_train,y_test):\n",
    "    import numpy as np\n",
    "\n",
    "# Predict class probabilities\n",
    "    y_pred_probs = model.predict(X_train)\n",
    "\n",
    "    # Convert probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_train,axis=1 )\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Optionally get class labels from encoder\n",
    "    class_names = le.classes_\n",
    "\n",
    "    # Plot\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix Train data CNN \"+spec +\" for \" + satellite)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=6)\n",
    "    print('AUC:',metrics.auc(fpr, tpr))\n",
    "    print('Accuracy: ',metrics.accuracy_score(y_true, y_pred))\n",
    "    print('R2',r2_score(y_true,y_pred))\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "\n",
    "    # Convert probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test,axis=1 )\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Optionally get class labels from encoder\n",
    "    class_names = le.classes_\n",
    "\n",
    "    # Plot\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix Test data CNN \"+spec +\" for \" + satellite)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=6)\n",
    "    print('AUC:',metrics.auc(fpr, tpr))\n",
    "    print('Accuracy: ',metrics.accuracy_score(y_true, y_pred))\n",
    "    print('R2',r2_score(y_true,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac936a08",
   "metadata": {},
   "source": [
    "<h1>Spectral CNN model </h1>\n",
    "Spectral CNN model extracts features of each spectral signatuere and use timeseries of spectral features for predicting WQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Train/test split\n",
    " \n",
    " \n",
    "# One-hot encode labels\n",
    "spec='spectral'\n",
    "le = LabelEncoder()\n",
    "y1 = le.fit_transform(y)\n",
    "num_classes = len(np.unique(y1))\n",
    "y_cat = to_categorical(y1, num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_spectral, y_cat, test_size=0.2, random_state=42, stratify=y_cat\n",
    "    )\n",
    "\n",
    " \n",
    "model_spectral,history_spectral=train_model(X_train,X_test,y_train,y_test)\n",
    "plot_history(history_spectral)\n",
    "plot_confusion_matrix(model_spectral, X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b8d76",
   "metadata": {},
   "source": [
    "<h1>Temporal model</h1>\n",
    "To train model performing convvolution in temporal dimension we must transpose the data so that concvolution  is performed on each band timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Train/test split\n",
    " \n",
    " \n",
    "# One-hot encode labels\n",
    "X_temporal = np.transpose(X_spectral, (0, 2, 1))\n",
    "\n",
    "time_steps = X_spectral.shape[1]\n",
    "n_features = X_spectral.shape[2]\n",
    " \n",
    "le = LabelEncoder()\n",
    "y1 = le.fit_transform(y)\n",
    "num_classes = len(np.unique(y1))\n",
    "y_cat = to_categorical(y1, num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_temporal, y_cat, test_size=0.2, random_state=42, stratify=y_cat\n",
    "    )\n",
    "spec=\"temporal\"\n",
    " \n",
    "model_temporal,history_temporal=train_model(X_train,X_test,y_train,y_test)\n",
    "plot_history(history_temporal)\n",
    "plot_confusion_matrix(model_temporal, X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4ce07",
   "metadata": {},
   "source": [
    "<h1>Future prediction</h1>\n",
    "The trained model can now be used to map water quality index based on timeseries of satellite images from any period. We use satellite images from  one  year period that is different than one the model is trained on. To use the model first we must extract satellite bands and format the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14300ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "base_path = future_path\n",
    "\n",
    "# --- Step 1: Extract folder dates and map to folder paths ---\n",
    "folder_date_map = {}\n",
    "for f in os.listdir(base_path):\n",
    "    full_path = os.path.join(base_path, f)\n",
    "    if os.path.isdir(full_path):\n",
    "        match = re.search(r\"(\\d{8})\", f)\n",
    "        if match:\n",
    "            date_obj = datetime.strptime(match.group(1), \"%Y%m%d\")\n",
    "            folder_date_map[date_obj] = full_path\n",
    "\n",
    "folder_dates = sorted(folder_date_map.keys())\n",
    "#print(folder_date_map)\n",
    "# --- Step 2: Use gdf from original WQ points for geometry   ---\n",
    " \n",
    "gdf=WQ_points.copy()\n",
    "# --- Helper to find nearest available folder date ---\n",
    "def find_nearest_date(target_date, date_list):\n",
    "    return min(date_list, key=lambda d: abs(d - target_date))\n",
    "\n",
    "# --- Step 3: Extract pixel values into separate band columns ---\n",
    "\n",
    "final1=[]\n",
    "for d in folder_date_map.keys():\n",
    "    folder_path=folder_date_map[d]\n",
    "    tiff_files = sorted([f for f in os.listdir(folder_path) if (f.lower().endswith('.tiff') or f.lower().endswith('.tif'))])\n",
    "     \n",
    "    for tiff_file in tiff_files:\n",
    "        # Extract band code from filename (e.g., 'B04')\n",
    "        if satellite==\"Planet_Scope\":\n",
    "            match_band = re.search(r'B(\\d{1,2}[A]?)', tiff_file)\n",
    "        else:\n",
    "            match_band = re.search(r'_B(\\d+[A]?)_', tiff_file)\n",
    "        if match_band:\n",
    "            band_code = \"B\" + match_band.group(1)\n",
    "\n",
    "            if band_code in band_names:\n",
    "                #print(d,band_code)\n",
    "                with rasterio.open(os.path.join(folder_path, tiff_file)) as src:\n",
    "                    # Ensure CRS matches\n",
    "                    \n",
    "                        \n",
    "                    for idx, row  in gdf.iterrows():\n",
    "                        \n",
    "                        point = gdf.to_crs(src.crs).iloc[idx].geometry\n",
    "                        if gdf.crs != src.crs:\n",
    "                            point = gdf.to_crs(src.crs).iloc[idx].geometry\n",
    "                        #print(list(src.sample([(point.x, point.y)])))\n",
    "                        val = list(src.sample([(point.x, point.y)]))[0][0]\n",
    "                        final1.append({'ponit':point,'pontid':idx,'date':d,'band':band_code,'val':val,'WQI':row['WQI'],\t'Class': row.Class})\n",
    "\n",
    "                         \n",
    "                \n",
    "     \n",
    "tsdf=pd.DataFrame(final1)\n",
    "\n",
    "\n",
    "# Make sure date is datetime\n",
    "tsdf['date'] = pd.to_datetime(tsdf['date'])\n",
    "\n",
    "# Pivot: one row per (pontid, date), columns are bands\n",
    "df_wide = tsdf.pivot_table(\n",
    "    index=['pontid',  'date', 'WQI', 'Class'],\n",
    "    columns='band',\n",
    "    values='val'\n",
    ").reset_index()\n",
    "\n",
    "# Sort only by pontid (integer) and date\n",
    "df_wide = df_wide.sort_values(['pontid', 'date'])\n",
    "\n",
    "# Get list of band names in sorted order\n",
    "band_names = sorted([c for c in df_wide.columns if c not in ['pontid', 'date','Class', 'WQI']])\n",
    "band_names  \n",
    "X_list = []\n",
    "ids_list = []\n",
    "dates_list = []\n",
    "class_list={}\n",
    "Wqi={}\n",
    "for pid, group in df_wide.groupby('pontid'):\n",
    "    group = group.sort_values('date')\n",
    "    ts_array = group[band_names].to_numpy(dtype=np.float32)  # shape: (num_times, num_bands)\n",
    "    X_list.append(ts_array)\n",
    "    ids_list.append(pid)\n",
    "    dates_list.append(group['date'].to_numpy())\n",
    "    class_list[pid]=int(group['Class'].max())\n",
    "  \n",
    "    Wqi[pid]=group['WQI'].max()\n",
    "max_len = max(ts.shape[0] for ts in X_list)\n",
    "num_bands = len(band_names)\n",
    "\n",
    "# Pad sequences on time axis\n",
    "X_padded = pad_sequences(\n",
    "    X_list,\n",
    "    maxlen=max_len,\n",
    "    dtype='float32',\n",
    "    padding='post',\n",
    "    value=0.0\n",
    ")  # shape: (num_points, max_len, num_bands)\n",
    "X_spectral_future = np.transpose(X_padded, (0, 2, 1))\n",
    "spec1=\"spectral\"\n",
    "# shape: (num_points, num_bands, max_len)\n",
    "X_spectral_future.shape \n",
    "X_temporal_future = np.transpose(X_spectral_future, (0, 2, 1))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55a8cb",
   "metadata": {},
   "source": [
    "<h1>Use model</h1>\n",
    "Predict the WQI for selected points and store the prediction in shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(satellite,spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc275e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec=\"spectral\"\n",
    "spec=\"temporal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27122ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spec==\"spectral\":    \n",
    "    y_future=model_spectral.predict(X_spectral_future\n",
    "                           )\n",
    "else:\n",
    "     y_future=model_temporal.predict(X_temporal_future )\n",
    "\n",
    "                          \n",
    "y_indices = np.argmax(y_future, axis=1) \n",
    "y_classes=le.inverse_transform(y_indices)\n",
    "y_classes\n",
    "WQ_points['predicted']=y_classes\n",
    "WQ_points.to_file('predicted_'+satellite+'_'+spec+'4.shp',driver=\"ESRI Shapefile\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
